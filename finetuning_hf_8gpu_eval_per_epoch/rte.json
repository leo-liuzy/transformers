{
  "per_device_train_batch_size": 2,
  "per_device_eval_batch_size": 2,
  "learning_rate": 2e-05,
  "weight_decay": 0.1,
  "adam_beta1": 0.9,
  "adam_beta2": 0.98,
  "adam_epsilon": 1e-06,
  "warmup_steps": 122,
  "num_train_epochs": 10,
  "hidden_dropout_prob": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "task_name": "rte",
  "max_seq_length": 512,
  "overwrite_output_dir": true,
  "do_train": true,
  "do_eval": true,
  "do_predict": true,
  "evaluation_strategy": "epoch",
  "save_strategy": "epoch",
  "gradient_accumulation_steps": 1,
  "max_grad_norm": 1.0,
  "lr_scheduler_type": "polynomial",
  "seed": 4,
  "fp16": true,
  "fp16_full_eval": true
}